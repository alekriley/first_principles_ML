{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy.optimize as opt\n",
    "import scipy.stats as sts\n",
    "import sklearn.gaussian_process as gp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BayesianOptimizer:\n",
    "    def __init__(self,length=1.,variance=1.,noise=1e-6,n_restarts=9):\n",
    "        self.n_restarts = n_restarts\n",
    "        self.kernel = gp.kernels.ConstantKernel(constant_value=variance,constant_value_bounds=(1e-5,1e5))*\\\n",
    "                        gp.kernels.Matern(length_scale=length,length_scale_bounds=(1e-5,1e5),nu=1.5)+\\\n",
    "                        gp.kernels.WhiteKernel(noise_level=noise,noise_level_bounds=(1e-5,1e5))\n",
    "        self.gpr = gp.GaussianProcessRegressor(alpha=0.,kernel=self.kernel,n_restarts_optimizer=self.n_restarts)\n",
    "    def __expected_improvement(self,candidate,seen,epsilon):\n",
    "        [prediction,std] = [c.ravel()[0] for c in self.gpr.predict(candidate,return_std=True)]\n",
    "        best_so_far = np.min(self.gpr.predict(seen))\n",
    "        if std>0:\n",
    "            z = (-prediction+best_so_far-epsilon)/std\n",
    "            return (-prediction+best_so_far-epsilon)*sts.norm.cdf(z)+std*sts.norm.pdf(z)\n",
    "        return 0.\n",
    "    def optimize(self,n_iterations,initial1,initial2,bounds,apply,cost_function,*cost_args):\n",
    "        '''\n",
    "            Example Inputs\n",
    "            regression_coefficient,learning_rate,num_neurons,batch_size\n",
    "            initial1 -> [0.0,0.005,6,64]\n",
    "            initial2 -> [0.5,0.01,12,32]\n",
    "            bounds -> [(0.,3.),(0.0005,0.02),(5,15),(32,256)]\n",
    "            apply -> [None,None,round,round]\n",
    "        '''\n",
    "        cost = np.array([cost_function(*initial1,*cost_args),cost_function(*initial2,*cost_args)])\n",
    "        x = np.array([initial1,initial2])\n",
    "        \n",
    "        \n",
    "        def propose_candidate(x,bounds,epsilon):\n",
    "            def negative_expected_improvement(candidate):\n",
    "                return -self.__expected_improvement(np.array([candidate]),x,epsilon)\n",
    "            min_val = 10e5\n",
    "            best_x = None\n",
    "            for _ in range(self.n_restarts):\n",
    "                initial_candidate = [np.random.uniform(low=l,high=u) for (l,u) in bounds]\n",
    "                res = opt.minimize(negative_expected_improvement,initial_candidate,bounds=bounds,method='L-BFGS-B')\n",
    "                if res.success:\n",
    "                    if res.fun < min_val:\n",
    "                        min_val = res.fun\n",
    "                        best_x = res.x\n",
    "            return best_x\n",
    "        \n",
    "        for _ in range(n_iterations):\n",
    "            self.gpr.fit(x,cost[:,None])\n",
    "            \n",
    "            next_x = [fnc(val) if fnc is not None else val for val,fnc in zip(propose_candidate(x,bounds,1e-8),apply)]\n",
    "            next_cost = cost_function(*next_x,*cost_args)\n",
    "            x = np.concatenate([x,np.array([next_x])],0)\n",
    "            cost = np.concatenate([cost,np.array([next_cost])])\n",
    "        \n",
    "        return [fnc(val) if fnc is not None else val for val,fnc in zip(x[np.argmin(cost)],apply)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
